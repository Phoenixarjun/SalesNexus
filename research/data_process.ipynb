{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f12f68",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abd59f2",
   "metadata": {},
   "source": [
    "<p> First we will Load the data using data Loader </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16527232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Arjun_Works\\\\SalesNexus\\\\research'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ad15882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Arjun_Works\\\\SalesNexus'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1be1cce",
   "metadata": {},
   "source": [
    "<p> Loading the Data </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f6fcab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-23 21:52:56,588: INFO: main_utils: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-06-23 21:52:56,591: INFO: main_utils: created directory at: artifacts]\n",
      "[2025-06-23 21:52:56,593: INFO: main_utils: created directory at: artifacts/data_acquisition]\n",
      "âœ… All files already present in: artifacts\\data_acquisition. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from ml_service.components.data_loader import DataLoader\n",
    "from ml_service.config.configuration import ConfigurationManager\n",
    "from ml_service.constants import *\n",
    "\n",
    "config_manager = ConfigurationManager(CONFIG_FILE_PATH)\n",
    "data_acquisition_config = config_manager.get_data_acquisition_config()\n",
    "\n",
    "loader = DataLoader(\n",
    "    data_dir=Path(data_acquisition_config.local_dir),\n",
    "    source=data_acquisition_config.source,\n",
    "    data_files=data_acquisition_config.data_files,\n",
    "    dataset_name=data_acquisition_config.dataset_name\n",
    ")\n",
    "\n",
    "loader.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f021f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“¥ Loading: artifacts\\data_acquisition\\train.csv\n",
      "ðŸ“¥ Loading: artifacts\\data_acquisition\\test.csv\n",
      "ðŸ“¥ Loading: artifacts\\data_acquisition\\stores.csv\n",
      "ðŸ“¥ Loading: artifacts\\data_acquisition\\oil.csv\n",
      "ðŸ“¥ Loading: artifacts\\data_acquisition\\holidays_events.csv\n",
      "ðŸ“¥ Loading: artifacts\\data_acquisition\\transactions.csv\n"
     ]
    }
   ],
   "source": [
    "train_df = loader.load(\"train\")\n",
    "test_df = loader.load(\"test\")\n",
    "stores_df = loader.load(\"stores\")\n",
    "oil_df = loader.load(\"oil\")\n",
    "holidays_events_df = loader.load(\"holidays_events\")\n",
    "transactions_df = loader.load(\"transactions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad8eadb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  store_nbr      family  sales  onpromotion\n",
       "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0\n",
       "1   1  2013-01-01          1   BABY CARE    0.0            0\n",
       "2   2  2013-01-01          1      BEAUTY    0.0            0\n",
       "3   3  2013-01-01          1   BEVERAGES    0.0            0\n",
       "4   4  2013-01-01          1       BOOKS    0.0            0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1114713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000889</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000890</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000891</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000892</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        date  store_nbr      family  onpromotion\n",
       "0  3000888  2017-08-16          1  AUTOMOTIVE            0\n",
       "1  3000889  2017-08-16          1   BABY CARE            0\n",
       "2  3000890  2017-08-16          1      BEAUTY            2\n",
       "3  3000891  2017-08-16          1   BEVERAGES           20\n",
       "4  3000892  2017-08-16          1       BOOKS            0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cf40165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataPreprocessingConfig:\n",
    "    \"\"\"Config for preprocessing data.\"\"\"\n",
    "    root_dir: Path\n",
    "    train_file: Path\n",
    "    test_file: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50b03a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_service.constants import *\n",
    "from ml_service.utils.main_utils import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a51de277",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(self, config_filepath: str):\n",
    "        \"\"\"Initialize the configuration manager.\n",
    "\n",
    "        Args:\n",
    "            config_filepath (str): Path to the main configuration file (YAML).\n",
    "        \"\"\"\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_data_preprocessing_config(self) -> DataPreprocessingConfig:\n",
    "        \"\"\"Get the configuration for data preprocessing.\n",
    "\n",
    "        Returns:\n",
    "            DataPreprocessingConfig: Paths for train and test preprocessed files.\n",
    "        \"\"\"\n",
    "        config = self.config.data_preprocessing\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        return DataPreprocessingConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            train_file=Path(config.root_dir) / config.train_file,\n",
    "            test_file=Path(config.root_dir) / config.test_file\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d01b41",
   "metadata": {},
   "source": [
    "<p>Letâ€™s merge the train, stores, and transactions data (and similarly for the test set) for better clarity.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8dbb03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merge_df = train_df.merge(stores_df, on='store_nbr', how='left')\n",
    "train_merge_df = train_merge_df.merge(transactions_df, on=['store_nbr','date'], how='left')\n",
    "\n",
    "test_merge_df = test_df.merge(stores_df, on='store_nbr', how='left')\n",
    "test_merge_df = test_merge_df.merge(transactions_df, on=['store_nbr','date'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7a35197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  store_nbr      family  sales  onpromotion   city  \\\n",
       "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0  Quito   \n",
       "1   1  2013-01-01          1   BABY CARE    0.0            0  Quito   \n",
       "2   2  2013-01-01          1      BEAUTY    0.0            0  Quito   \n",
       "3   3  2013-01-01          1   BEVERAGES    0.0            0  Quito   \n",
       "4   4  2013-01-01          1       BOOKS    0.0            0  Quito   \n",
       "\n",
       "       state type  cluster  transactions  \n",
       "0  Pichincha    D       13           NaN  \n",
       "1  Pichincha    D       13           NaN  \n",
       "2  Pichincha    D       13           NaN  \n",
       "3  Pichincha    D       13           NaN  \n",
       "4  Pichincha    D       13           NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a221b572",
   "metadata": {},
   "source": [
    "<p>Now, Letâ€™s merge the holidays_events and oil data (and similarly for the test set) for Date-level features.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2dbd06b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_events_oil_merge_df = oil_df.merge(holidays_events_df, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a206049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>type</th>\n",
       "      <th>locale</th>\n",
       "      <th>locale_name</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>93.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>92.97</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>93.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>93.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  dcoilwtico     type    locale locale_name         description  \\\n",
       "0  2013-01-01         NaN  Holiday  National     Ecuador  Primer dia del ano   \n",
       "1  2013-01-02       93.14      NaN       NaN         NaN                 NaN   \n",
       "2  2013-01-03       92.97      NaN       NaN         NaN                 NaN   \n",
       "3  2013-01-04       93.12      NaN       NaN         NaN                 NaN   \n",
       "4  2013-01-07       93.20      NaN       NaN         NaN                 NaN   \n",
       "\n",
       "  transferred  \n",
       "0       False  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holidays_events_oil_merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8e5a9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final = train_merge_df.merge(holidays_events_oil_merge_df, on='date', how='left')\n",
    "test_final = test_merge_df.merge(holidays_events_oil_merge_df, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7fb1c398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type_x</th>\n",
       "      <th>cluster</th>\n",
       "      <th>transactions</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>type_y</th>\n",
       "      <th>locale</th>\n",
       "      <th>locale_name</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>National</td>\n",
       "      <td>Ecuador</td>\n",
       "      <td>Primer dia del ano</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  store_nbr      family  sales  onpromotion   city  \\\n",
       "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0  Quito   \n",
       "1   1  2013-01-01          1   BABY CARE    0.0            0  Quito   \n",
       "2   2  2013-01-01          1      BEAUTY    0.0            0  Quito   \n",
       "3   3  2013-01-01          1   BEVERAGES    0.0            0  Quito   \n",
       "4   4  2013-01-01          1       BOOKS    0.0            0  Quito   \n",
       "\n",
       "       state type_x  cluster  transactions  dcoilwtico   type_y    locale  \\\n",
       "0  Pichincha      D       13           NaN         NaN  Holiday  National   \n",
       "1  Pichincha      D       13           NaN         NaN  Holiday  National   \n",
       "2  Pichincha      D       13           NaN         NaN  Holiday  National   \n",
       "3  Pichincha      D       13           NaN         NaN  Holiday  National   \n",
       "4  Pichincha      D       13           NaN         NaN  Holiday  National   \n",
       "\n",
       "  locale_name         description transferred  \n",
       "0     Ecuador  Primer dia del ano       False  \n",
       "1     Ecuador  Primer dia del ano       False  \n",
       "2     Ecuador  Primer dia del ano       False  \n",
       "3     Ecuador  Primer dia del ano       False  \n",
       "4     Ecuador  Primer dia del ano       False  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bef76ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "date                  0\n",
       "store_nbr             0\n",
       "family                0\n",
       "sales                 0\n",
       "onpromotion           0\n",
       "city                  0\n",
       "state                 0\n",
       "type_x                0\n",
       "cluster               0\n",
       "transactions     248358\n",
       "dcoilwtico       933768\n",
       "type_y          2680128\n",
       "locale          2680128\n",
       "locale_name     2680128\n",
       "description     2680128\n",
       "transferred     2680128\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5103c393",
   "metadata": {},
   "source": [
    "###  Dropping Lowâ€‘Value Features\n",
    "\n",
    "We drop the following columns:\n",
    "\n",
    "* **`description`**, **`locale_name`**, **`locale`**, and **`transferred`**\n",
    "\n",
    "#### âœ… Why?\n",
    "\n",
    "* These fields contain textual or highly sparse information that **doesnâ€™t directly affect sales prediction**.\n",
    "* They introduce **noise** and **high cardinality**, making it harder for the model to learn meaningful patterns.\n",
    "* Similar information (holidays) is already captured by the **`type`** column, making these redundant.\n",
    "\n",
    "#### ðŸ’¡ Result\n",
    "\n",
    "By removing these columns, we:\n",
    "\n",
    "* **Improve training efficiency** (smaller, cleaner dataset).\n",
    "* Reduce the risk of overfitting.\n",
    "* Maintain focus on the features that matter for forecasting sales.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e5b74e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final.drop(columns=['description', 'locale_name', 'locale', 'transferred'], inplace=True)\n",
    "test_final.drop(columns=['description', 'locale_name', 'locale', 'transferred'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75f07f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type_x</th>\n",
       "      <th>cluster</th>\n",
       "      <th>transactions</th>\n",
       "      <th>dcoilwtico</th>\n",
       "      <th>type_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Holiday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  store_nbr      family  sales  onpromotion   city  \\\n",
       "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0  Quito   \n",
       "1   1  2013-01-01          1   BABY CARE    0.0            0  Quito   \n",
       "2   2  2013-01-01          1      BEAUTY    0.0            0  Quito   \n",
       "3   3  2013-01-01          1   BEVERAGES    0.0            0  Quito   \n",
       "4   4  2013-01-01          1       BOOKS    0.0            0  Quito   \n",
       "\n",
       "       state type_x  cluster  transactions  dcoilwtico   type_y  \n",
       "0  Pichincha      D       13           NaN         NaN  Holiday  \n",
       "1  Pichincha      D       13           NaN         NaN  Holiday  \n",
       "2  Pichincha      D       13           NaN         NaN  Holiday  \n",
       "3  Pichincha      D       13           NaN         NaN  Holiday  \n",
       "4  Pichincha      D       13           NaN         NaN  Holiday  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8dc43bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3032964, 13)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2492906d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                    0\n",
       "date                  0\n",
       "store_nbr             0\n",
       "family                0\n",
       "sales                 0\n",
       "onpromotion           0\n",
       "city                  0\n",
       "state                 0\n",
       "type_x                0\n",
       "cluster               0\n",
       "transactions     248358\n",
       "dcoilwtico       933768\n",
       "type_y          2680128\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_final.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8f0a08",
   "metadata": {},
   "source": [
    "<p> We impute transactions due to its high predictive potential, while dropping columns with excessive sparsity and low information value. </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98c72973",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_merge_df.drop(columns=['dcoilwtico', 'type_y'], inplace=True, errors='ignore')\n",
    "test_merge_df.drop(columns=['dcoilwtico', 'type_y'], inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af2fd4e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                   0\n",
       "date                 0\n",
       "store_nbr            0\n",
       "family               0\n",
       "sales                0\n",
       "onpromotion          0\n",
       "city                 0\n",
       "state                0\n",
       "type                 0\n",
       "cluster              0\n",
       "transactions    245784\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9decf37",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82731425",
   "metadata": {},
   "source": [
    "Note: Since transactions is the only column with missing values, we'll apply an imputation technique (such as filling with median or other suitable method) during the Data Transformation phase, where we'll also handle scaling, encoding, and splitting of the dataset. This ensures a clean and robust workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90870d7d",
   "metadata": {},
   "source": [
    "<p>Now Let's look for duplicate values and handle them </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d1170e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_merge_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4958a3",
   "metadata": {},
   "source": [
    "<p>Since the data is clean  with no duplicate rows and no significant missing values (other than the <code>transactions</code> column, which we'll impute later) we can now move on to the next phase of the pipeline.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3b3fe684",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = data_acquisition_config.local_dir\n",
    "\n",
    "train_merge_df.to_csv(data_folder / \"train_merge.csv\", index=False)\n",
    "test_merge_df.to_csv(data_folder / \"test_merge.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2afa159b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "\n",
    "class DataProcessor:\n",
    "    \"\"\"Perform merging, cleaning, and exporting of Store Sales Time Series data.\"\"\"\n",
    "\n",
    "    def __init__(self, data_dir: Path, data_files: Dict[str, str]) -> None:\n",
    "        self.data_dir = data_dir\n",
    "        self.data_files = data_files\n",
    "        self.data = {}  # Will hold all DF references\n",
    "\n",
    "    def load(self) -> \"DataProcessor\":\n",
    "        \"\"\"Load all files from the data directory.\"\"\"\n",
    "        self.data = {name: pd.read_csv(self.data_dir / path) for name, path in self.data_files.items()}\n",
    "        return self\n",
    "\n",
    "    def merge_train_test(self) -> \"DataProcessor\":\n",
    "        \"\"\"Merge train/test with stores and transactions.\"\"\"\n",
    "        self.data[\"train_merged\"] = (\n",
    "            self.data[\"train\"]\n",
    "            .merge(self.data[\"stores\"], on=\"store_nbr\", how=\"left\")\n",
    "            .merge(self.data[\"transactions\"], on=[\"store_nbr\", \"date\"], how=\"left\")\n",
    "        )\n",
    "        self.data[\"test_merged\"] = (\n",
    "            self.data[\"test\"]\n",
    "            .merge(self.data[\"stores\"], on=\"store_nbr\", how=\"left\")\n",
    "            .merge(self.data[\"transactions\"], on=[\"store_nbr\", \"date\"], how=\"left\")\n",
    "        )\n",
    "        return self\n",
    "\n",
    "    def merge_holidays_and_oil(self) -> \"DataProcessor\":\n",
    "        \"\"\"Merge holidays and oil data for final train/test.\"\"\"\n",
    "        holidays_oil_merged = self.data[\"oil\"].merge(self.data[\"holidays_events\"], on=\"date\", how=\"left\")\n",
    "        self.data[\"train_final\"] = self.data[\"train_merged\"].merge(holidays_oil_merged, on=\"date\", how=\"left\")\n",
    "        self.data[\"test_final\"] = self.data[\"test_merged\"].merge(holidays_oil_merged, on=\"date\", how=\"left\")\n",
    "        return self\n",
    "\n",
    "    def drop_irrelevant_columns(self) -> \"DataProcessor\":\n",
    "        \"\"\"Drop low-value and sparse columns.\"\"\"\n",
    "        drop_cols = [\"description\", \"locale_name\", \"locale\", \"transferred\", \"dcoilwtico\", \"type_y\"]\n",
    "        self.data[\"train_final\"] = self.data[\"train_final\"].drop(columns=drop_cols, errors=\"ignore\")\n",
    "        self.data[\"test_final\"] = self.data[\"test_final\"].drop(columns=drop_cols, errors=\"ignore\")\n",
    "        return self\n",
    "\n",
    "    def save(self) -> \"DataProcessor\":\n",
    "        \"\"\"Save final merged train and test files.\"\"\"\n",
    "        self.data[\"train_final\"].to_csv(self.data_dir / \"train_merge.csv\", index=False)\n",
    "        self.data[\"test_final\"].to_csv(self.data_dir / \"test_merge.csv\", index=False)\n",
    "\n",
    "        print(f\"âœ… Final train and test files saved to: {self.data_dir}\")\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b8c1d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-06-23 21:53:16,159: INFO: main_utils: yaml file: config\\config.yaml loaded successfully]\n",
      "[2025-06-23 21:53:16,161: INFO: main_utils: created directory at: artifacts]\n",
      "[2025-06-23 21:53:16,163: INFO: main_utils: created directory at: artifacts/data_acquisition]\n",
      "âœ… Final train and test files saved to: artifacts\\data_acquisition\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.DataProcessor at 0x1bceff41b70>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from ml_service.config.configuration import ConfigurationManager\n",
    "\n",
    "config_manager = ConfigurationManager(CONFIG_FILE_PATH)  \n",
    "data_acquisition_config = config_manager.get_data_acquisition_config()\n",
    "\n",
    "data_dir = Path(data_acquisition_config.local_dir)  \n",
    "files = data_acquisition_config.data_files\n",
    "\n",
    "# Chain methods for a clean pipeline\n",
    "DataProcessor(data_dir, files) \\\n",
    "    .load() \\\n",
    "    .merge_train_test() \\\n",
    "    .merge_holidays_and_oil() \\\n",
    "    .drop_irrelevant_columns() \\\n",
    "    .save()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chest-cancer-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
